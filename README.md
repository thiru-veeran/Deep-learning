# Deep-learning
gradient_descent_algorithms.ipynb we will anlayze the working mechanism of Gradient Descent, Stochastic Gradient Descent, Momentum Based,Adagrad, Rmsprop etc.
In DeepCnn.ipynb we will classify cifar-10 datset using pretrained models. We will see how to customize the layers of pretrained models according to our dataset etc using pytorch.
In Rnns.ipynb we will see rnn, lstm, gru working mechanism by using name2lang2.txt dataset
In BatchSeqModels.ipynb we will see how to train the network in batch amount
In EncoderDecoderArchitecture.ipynb we will see how to use encoder information in the decoder and how to add attention mechanism on top of encoder using NEWS2012-Training-EnHi-13937.txt, NEWS2012-Ref-EnHi-1000.xml dataset
